# Установка
?

# Использование
Обучение в auDeep производится в несколько отдельных этапов: 
1. Извлечение спектрограмм и метаданных набора данных из необработанных аудиофайлов (`audeep preprocess`)
2. Обучение DNN на извлеченных спектрограммах (`audeep ... train`)
3. Генерация признаков с использованием обученного DNN (`audeep ... generate`)
4. Оценка сгенерированных признаков (`audeep ... evaluate`)
5. Экспорт сгенерированных признаков в CSV/ARFF (`audeep export`)

## 0. Получение данных для обучения
Мы используем [ESC-10 датасет](https://github.com/karoldvl/ESC-10) для классификации звуков окружающей среды, которое содержит 400 экземпляров из 10 классов. В командной строке перейдите в директорию по вашему выбору. В дальнейшем мы будем предполагать, что любые команды выполняются из директории, выбранной на этом шаге. Получить набор данных ESC-10 из Github с помощью следующих команд:
```shell script
git clone https://github.com/karoldvl/ESC-10.git
pushd ESC-10
git checkout 553c8f1743b9dba6b282e1323c3ca8fa76923448
popd
```
Это сохранит набор данных в директории с именем `ESC-10`. Поскольку исходный репозиторий ESC-10 был объединен с репозиторием ESC-50, мы должны вручную извлечь правильный коммит.

## 1. Извлечение спектрограмм
Для начала, нам нужно извлечь спектрограммы и некоторые метаданные из необработанных аудиофайлов, которые мы загрузили на предыдущем шаге. Чтобы получить общий обзор аудиофайлов, содержащихся в наборе данных, мы можем использовать следующую команду.
```shell script
audeep inspect raw --basedir ESC-10
```
Эта команда выведет несколько сообений и таблицу, содержащую информацию о наборе данных.

Далее мы собираемся определить подходящие параметры для извлечения спектрограммы. <...> В качестве разумной отправной точки для набора данных `ESC-10` мы рекомендуем использовать FFT-окна шириной 80 мс с перекрытием 40 мс и полосами частот 128 мел.

Визуальная обратная связь очень помогает в выборе параметров для извлечения спектрограммы. 
С помощью следующей команды можно быстро построить спектрограммы с параметрами, рекомендованными выше.
```shell script
audeep preprocess \
--basedir ESC-10 \
--window-width 0.08 \
--window-overlap 0.04 \
--mel-spectrum 128 \
--fixed-length 5 \
--pretend 10
```
Следующая команда откроет окно с графиком спектрограммы и гистограммой амплитуды, показывающей распределение амплитуд по шкале дБ (auDeep нормализует спектрограммы до 0 дБ).
```shell script
audeep preprocess
--basedir ESC-10 \
--window-width 0.08 \
--window-overlap 0.04 \
--mel-spectrum 128 \
--fixed-length 5 \
--clip-below -60 \
--pretend 10
```

Когда выбор параметров окончен, можно начать извлечение спектрограммы для полного набора данных:
```shell script
audeep preprocess \
--basedir ESC-10 \
--window-width 0.08 \
--window-overlap 0.04 \
--mel-spectrum 128 \
--fixed-length 5 \
--clip-below -60 \
--output spectrograms/esc-10-0.08-0.04-128-60.nc
```
После завершения команды извлеченные спектрограммы будут сохранены в формате [netCDF 4](https://www.unidata.ucar.edu/software/netcdf/) в файле с именем `spectrograms/esc-10-0.08-0.04- 128-60.nc`. Кроме того, поскольку auDeep распознает набор данных ESC-10, метки экземпляров и предопределенная настройка перекрестной проверки сохраняются вместе со спектрограммами.

## 2. Обучение DNN на извлеченных спектрограммах (автоэнкодера)
Далее, мы собираемся обучить рекуррентную последовательность для автоматического кодирования последовательности на спектрограммах, извлеченных на предыдущем шаге.

| Параметр | Описание | 
| -------- | -------- |
| `--num-layers` | Количество слоёв |
| `--num-units 256` | Количество ячеек GRU в кодере и декодере |
| `--bidirectional-decoder` | Двунаправленный декодер RNN |
| `--num-epochs` | Количество эпох |
| `--learning-rate` | Скорость обучения |
| `--keep-prob 0.8` | Отсев 20% |
| `--batch-size` | Размер партии |

```shell script
audeep t-rae train \
--input spectrograms/esc-10-0.08-0.04-128-60.nc \
--run-name output/esc-10-0.08-0.04-128-60/t-2x256-x-b \
--num-epochs 64 \
--batch-size 64 \
--learning-rate 0.001 \
--keep-prob 0.8 \
--num-layers 2 \
--num-units 256 \
--bidirectional-decoder
```

## 3. Генерация признаков
После того, как обучение закончено, обученный автоенкодер может использоваться для генерации признаков из спектрограмм.
```shell script
audeep t-rae generate \
--model-dir output/esc-10-0.08-0.04-128-60/t-2x256-x-b/logs \
--input spectrograms/esc-10-0.08-0.04-128-60.nc \
--output output/esc-10-0.08-0.04-128-60/representations.nc
```
Команда извлечет изученное скрытое представление каждой спектрограммы в качестве вектора ее признаков и сохранит эти особенности в выходном файле.

## 4. Оценка признаков
Поскольку метки экземпляров и настройки перекрестной проверки были сохранены, теперь мы можем использовать их для оценки простого классификатора по изученным представлениям. Мы будем использовать встроенный многослойный персептрон (MLP) для классификации, с 2 скрытыми слоями (`--num-layer 2`) и 150 скрытыми единицами на слой (` --num-units 150`). Обучение будет проводиться для 400 эпох (`--num-epochs 400`) со скоростью обучения 0,001 (` --learning-rate 0,001`) и 40% отсева (`--keep-prob 0.6`). Во время обучения MLP дозирование не используется.
```shell script
audeep mlp evaluate \
--input output/esc-10-0.08-0.04-128-60/representations.nc \
--cross-validate \
--shuffle \
--num-epochs 400 \
--learning-rate 0.001
--keep-prob 0.4 \
--num-layers 2 \
--num-units 150
```
Команда напечатает точность классификации на каждом перекрестном этапе проверки, а также среднюю точность классификации и матрицу путаницы.

## 5. Экспорт признаков
При желании, изученные представления могут быть экспортированы в CSV или ARFF для дальнейшей обработки, такой как классификация с альтернативным алгоритмом.
```shell script
audeep export \
--input output/esc-10-0.08-0.04-128-60/representations.nc \
--output output/esc-10-0.08-0.04-128-60/csv \
--format csv
```
